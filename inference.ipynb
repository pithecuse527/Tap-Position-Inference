{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t17qI1HT1IfP"
      },
      "source": [
        "---\n",
        "### TITLE: The Inference with Sensors\n",
        "### AUTHOR: Honggeun Ji\n",
        "### DATE: 10.Nov.2021.\n",
        "---\n",
        "\n",
        "# Tap Position Inference with Flutter and Keras\n",
        "<div>\n",
        "<img src=\"https://media.vlpt.us/images/swara/post/f984346a-d7a6-4ff7-981e-9b71de5d61c7/flutter.png\" width=\"200\"/>\n",
        "<img src=\"https://miro.medium.com/max/600/0*LZQf7b4u8f97izwV.png\" width=\"200\"/>\n",
        "</div>\n",
        "\n",
        "In this lab, I would like to show you the tap position inference using\n",
        "these two sensory data.\n",
        "\n",
        "*   Accelerometer Sensory Data\n",
        "*   Gyroscope Sensory Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW7aaco-6TeS"
      },
      "source": [
        "# Data Collection\n",
        "\n",
        "\n",
        "\n",
        "> **Q. What kinds of Sensory Data and How do we collect?**\n",
        "\n",
        "\n",
        "### What Data?\n",
        "**Inspired by Professor Li's \"Privacy Leakage in Smart Device\" introduction.**\n",
        "\n",
        "*   In general, there are three diffent types of sensors on mobile devices.\n",
        "\n",
        "         1. Accelerometer \n",
        "         2. Gyroscope\n",
        "         3. Magnetometer\n",
        "\n",
        "*   This lab only deals with those two sensors except the Magnetometer.\n",
        "\n",
        "*   Based on those two sensors, we may collect sensory data at the moment our user tapped a zone.\n",
        "*   The zones are divided into 12 parts; however, this lab will only show you the case of 6 tapping zone. (As I want to show you the testing case first, after this labs seems valid, I'll move on to the next stages.)\n",
        "\n",
        "</br>\n",
        "\n",
        "### Data, Data, Data... How to collect?\n",
        "**Inspired from Android App Development introduction.**\n",
        "\n",
        "\n",
        "*   The way how I develop an app is quite different from lagacy project.\n",
        "*   Typically, professional developers choose the native development way so that the app works powerfully. (High performance, Faster Reload, and using the native hardware)\n",
        "\n",
        "*   However, it requires at least 3 months to become confident on the native application development.\n",
        "*   This is the reason why I choose **Flutter**. The Flutter is a cross-platform development framework made by Google.\n",
        "*   Not that powerful than the native one, but **this still leads us to implement the sensor data.**\n",
        "*   Also, the Flutter use the programming language, **Dart**, which is quite similar with Java.\n",
        "*   Use the Flutter packages to capture the sensor data with tap position at the moment when a user tap those zone. \n",
        "\n",
        "</br>\n",
        "\n",
        "**Tapping the App looks like,**\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?id=1F-Od3yLodwsoKUzGqZ9Cww9kqAWPvP3w\" width=\"350\" height=\"500\">\n",
        "<img src=\"https://drive.google.com/uc?id=1jyhw4BWNRr8NckquDIZMLWWQ4v2A4QEf\" width=\"250\" height=\"500\">\n",
        "</div>\n",
        "\n",
        "</br>\n",
        "</br>\n",
        "</br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSwHZgTJaLPO"
      },
      "source": [
        "> **Q. How do we collect?**\n",
        "\n",
        "### Database Comes Here!\n",
        "\n",
        "*   Send those sensory data and tap position information to the Database.\n",
        "*   Here, I used FireStore from Google Firebase.\n",
        "\n",
        "</br>\n",
        "\n",
        "### What is Firestore?\n",
        "\n",
        "\n",
        "*   It is a Database based on NoSQL.\n",
        "*   Lightweight, Easy to store the data.\n",
        "*   Easy to export the data into .csv or .json form.\n",
        "*   Every record is regard as \"Document\".\n",
        "\n",
        "*   Firestore looks like this,\n",
        "<img src=\"https://drive.google.com/uc?id=1E4iyC5fTlCAWO_cJt6oOcoR7IQna_hvc\" width=\"950\" height=\"480\">\n",
        "\n",
        "*   My Flutter App will send those data set into this Firestore Database.\n",
        "</br>\n",
        "</br>\n",
        "</br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF9S8Gpcdo3r"
      },
      "source": [
        "# Data Ready\n",
        "\n",
        "### Tapping The Zone At Least 170 times\n",
        "*   Why 170 times? -> **In order to divide the training data and validation data appropriately.**\n",
        "*   Tap each 6 zones (zone 0, 2, 5, 6, 9 and 11) 170 times respectively.\n",
        "*   Flutter App will send the snapshot of the sensory data and tap position.\n",
        "\n",
        "</br>\n",
        "\n",
        "### After finished Tapping\n",
        "*   See the data has beend successfully collected.\n",
        "*   Showing the partial result\n",
        "\n",
        "</br>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1CwkwpQgJSXOOCoI58Mdoo3jQY4KMDyIU\" width=\"750\" height=\"550\">\n",
        "\n",
        "*   **Export the Firestore collection into .csv file**\n",
        "\n",
        "</br></br>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK8MtQOhglH1"
      },
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "1.   **Import Pandas package to use the .csv file**\n",
        "2.   **Open the .csv file and save it.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7bCcjLChcb6"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_all = pd.read_csv('sample_data/sensory_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuWkAac4hvde"
      },
      "source": [
        "3.   **Divide the *data_all* into *INPUT DATA* and *TARGET DATA***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeEd58cZiNaI"
      },
      "source": [
        "x = data_all.drop(['__id__', 'tapped_zone', 'tap_position_x', 'tap_position_y'], axis=1)  # Drop evertyig except sensory data\n",
        "y = data_all.tapped_zone  # only the tapping zone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eccGJAoOihDZ",
        "outputId": "465c3e8e-f90b-4b16-8257-cc174c8cb46c"
      },
      "source": [
        "# check out the division result\n",
        "x.sample(5)  # INPUT DATA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accelerometer1</th>\n",
              "      <th>accelerometer2</th>\n",
              "      <th>accelerometer3</th>\n",
              "      <th>gyroscope1</th>\n",
              "      <th>gyroscope2</th>\n",
              "      <th>gyroscope3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0.366364</td>\n",
              "      <td>1.141409</td>\n",
              "      <td>11.135806</td>\n",
              "      <td>-1.178547</td>\n",
              "      <td>2.324672</td>\n",
              "      <td>0.389782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>-2.278632</td>\n",
              "      <td>1.588522</td>\n",
              "      <td>10.676431</td>\n",
              "      <td>-1.782574</td>\n",
              "      <td>-2.572955</td>\n",
              "      <td>-0.294895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>-1.659253</td>\n",
              "      <td>1.448257</td>\n",
              "      <td>10.325320</td>\n",
              "      <td>-0.737805</td>\n",
              "      <td>-2.389644</td>\n",
              "      <td>-0.076489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>0.666183</td>\n",
              "      <td>-1.208701</td>\n",
              "      <td>10.582074</td>\n",
              "      <td>0.920327</td>\n",
              "      <td>-0.874574</td>\n",
              "      <td>-0.073958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.804355</td>\n",
              "      <td>0.300867</td>\n",
              "      <td>10.784247</td>\n",
              "      <td>-0.460065</td>\n",
              "      <td>1.309208</td>\n",
              "      <td>0.288467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     accelerometer1  accelerometer2  ...  gyroscope2  gyroscope3\n",
              "131        0.366364        1.141409  ...    2.324672    0.389782\n",
              "101       -2.278632        1.588522  ...   -2.572955   -0.294895\n",
              "337       -1.659253        1.448257  ...   -2.389644   -0.076489\n",
              "62         0.666183       -1.208701  ...   -0.874574   -0.073958\n",
              "47         0.804355        0.300867  ...    1.309208    0.288467\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPJnPB7GikEe",
        "outputId": "57d034b4-74db-4b63-d7cb-928791661623"
      },
      "source": [
        "# Don't worry about the matching, \n",
        "# division will be processed based on the original records.\n",
        "y.sample(5)  # TARGET DATA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "779    2.0\n",
              "520    6.0\n",
              "53     9.0\n",
              "679    2.0\n",
              "772    6.0\n",
              "Name: tapped_zone, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEfXzpL1izPH"
      },
      "source": [
        "4.   **Throw away the inappropriate record (if is missing column data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gxglWBKjgKZ"
      },
      "source": [
        "x = x.dropna()\n",
        "y = y.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ6hJIXLlh_B"
      },
      "source": [
        "5.   **Split the data into training and validating data (80:20):**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9xRhKqlltzK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, stratify=y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv2tmfuJkU7V"
      },
      "source": [
        "6. **One-Hot Encoding (In order to categorize in an array)**\n",
        "</br>\n",
        "</br>\n",
        "Brief concept of One-Hot Encoding\n",
        "</br>\n",
        "<img src=\"https://drive.google.com/uc?id=1rTFKopldrOD9VXxwSGh1iPeFrw_1f3X8\" width=\"2000\" height=\"200\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ6jOOBblWZo"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_train_encoded = tf.keras.utils.to_categorical(y_train)  # one-hot encoding for training target\n",
        "y_val_encoded = tf.keras.utils.to_categorical(y_val)      # one-hot encoding for validate target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W54laE47lYN8",
        "outputId": "c1315ee0-4ff4-42f1-da40-ed6a1f609632"
      },
      "source": [
        "# check out the shape\n",
        "print(y_train_encoded.shape, y_val_encoded.shape)\n",
        "print(x_train.shape, x_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(815, 12) (204, 12)\n",
            "(815, 6) (204, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FPR-IRxoA0k"
      },
      "source": [
        "## Preprocessing Done!\n",
        "\n",
        "*   Guess no need standardization as the scale of the input data is not that different.\n",
        "</br>\n",
        "</br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnOcc3gkpeKg"
      },
      "source": [
        "# Training\n",
        "1. **Simply build a neural network with two layers from Tensorflow Keras**\n",
        "\n",
        "</br>\n",
        "<img src=\"https://drive.google.com/uc?id=1eaw2YBh8L8SSXOoSTw1wrzt26Yuj79-C\" width=\"500\" height=\"300\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjzTM7O5n4d_"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()  # Entire Sequential Neural Network\n",
        "model.add(Dense(80, activation='sigmoid', input_shape=(6,), kernel_regularizer='l2'))  # Add the hidden layer with 80 unit(Neuron)\n",
        "model.add(Dense(12, activation='softmax'))  # Add the output layer (give us 12 classes)\n",
        "\n",
        "# optimizer is SGD (Stochastic Gradient Descent) with Learning Rate = 0.01 (default)\n",
        "# loss function should be categorical as this is the multiple classification problem\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGRtwiQerxD9"
      },
      "source": [
        "2.  **Start the training with preprocessed data (with 10 epochs)**\n",
        "\n",
        "*   Just checking out whether the training is possible or not\n",
        "*   If there are no problems with this training, the accuracy will be low, so we need to increase the epoch.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUe5J0xGr4oj",
        "outputId": "c85cb5a6-c5c9-4d27-9253-0db6cd2e723f"
      },
      "source": [
        "history = model.fit(x_train, y_train_encoded, epochs=10, validation_data=(x_val, y_val_encoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "26/26 [==============================] - 1s 9ms/step - loss: 2.4094 - accuracy: 0.1669 - val_loss: 2.2096 - val_accuracy: 0.1667\n",
            "Epoch 2/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.1202 - accuracy: 0.1681 - val_loss: 2.0378 - val_accuracy: 0.1716\n",
            "Epoch 3/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.9952 - accuracy: 0.1718 - val_loss: 1.9467 - val_accuracy: 0.1814\n",
            "Epoch 4/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.9216 - accuracy: 0.2356 - val_loss: 1.8868 - val_accuracy: 0.2745\n",
            "Epoch 5/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.8671 - accuracy: 0.3117 - val_loss: 1.8375 - val_accuracy: 0.3824\n",
            "Epoch 6/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.8207 - accuracy: 0.4221 - val_loss: 1.7936 - val_accuracy: 0.3627\n",
            "Epoch 7/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.7791 - accuracy: 0.4331 - val_loss: 1.7539 - val_accuracy: 0.3676\n",
            "Epoch 8/10\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.7408 - accuracy: 0.4123 - val_loss: 1.7177 - val_accuracy: 0.4461\n",
            "Epoch 9/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.7053 - accuracy: 0.4442 - val_loss: 1.6834 - val_accuracy: 0.6373\n",
            "Epoch 10/10\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.6713 - accuracy: 0.5301 - val_loss: 1.6508 - val_accuracy: 0.4902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJNPZM_tsA2V",
        "outputId": "13e7ecca-57bc-4e59-c623-453e761dcf9b"
      },
      "source": [
        "# check the keys of the training history\n",
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Mb_unYs2Oe"
      },
      "source": [
        "3.  **If there is no training error, check out the accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-IZ2Z9Us1d1",
        "outputId": "c09ff266-405e-472b-e107-4ec7c4ad90f1"
      },
      "source": [
        "loss, accuracy = model.evaluate(x_val, y_val_encoded, verbose=0)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1666666716337204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVCyR-LftI-3"
      },
      "source": [
        "4.  **Seems the training works but the accuracy is quite low (pointless...)**\n",
        "5.  **Increase the epoch and see the result**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U54CYvmUtYNC",
        "outputId": "abaee64c-d72c-4aca-94bc-be93bcc9b81b"
      },
      "source": [
        "history = model.fit(x_train, y_train_encoded, epochs=300, validation_data=(x_val, y_val_encoded))  # with 300 epochs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "26/26 [==============================] - 1s 10ms/step - loss: 2.2383 - accuracy: 0.1620 - val_loss: 2.0997 - val_accuracy: 0.1618\n",
            "Epoch 2/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.0483 - accuracy: 0.1485 - val_loss: 1.9941 - val_accuracy: 0.1863\n",
            "Epoch 3/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.9684 - accuracy: 0.2012 - val_loss: 1.9336 - val_accuracy: 0.1422\n",
            "Epoch 4/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.9152 - accuracy: 0.1706 - val_loss: 1.8862 - val_accuracy: 0.1471\n",
            "Epoch 5/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.8712 - accuracy: 0.1816 - val_loss: 1.8443 - val_accuracy: 0.1912\n",
            "Epoch 6/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.8304 - accuracy: 0.2859 - val_loss: 1.8065 - val_accuracy: 0.2549\n",
            "Epoch 7/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.7947 - accuracy: 0.3190 - val_loss: 1.7726 - val_accuracy: 0.4853\n",
            "Epoch 8/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.7592 - accuracy: 0.3755 - val_loss: 1.7378 - val_accuracy: 0.4559\n",
            "Epoch 9/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.7260 - accuracy: 0.4761 - val_loss: 1.7046 - val_accuracy: 0.5049\n",
            "Epoch 10/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.6930 - accuracy: 0.5006 - val_loss: 1.6720 - val_accuracy: 0.6275\n",
            "Epoch 11/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.6597 - accuracy: 0.5706 - val_loss: 1.6418 - val_accuracy: 0.6176\n",
            "Epoch 12/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.6271 - accuracy: 0.4920 - val_loss: 1.6114 - val_accuracy: 0.6373\n",
            "Epoch 13/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.5988 - accuracy: 0.5828 - val_loss: 1.5809 - val_accuracy: 0.5441\n",
            "Epoch 14/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.5701 - accuracy: 0.5411 - val_loss: 1.5523 - val_accuracy: 0.6127\n",
            "Epoch 15/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.5412 - accuracy: 0.5669 - val_loss: 1.5240 - val_accuracy: 0.6373\n",
            "Epoch 16/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.5135 - accuracy: 0.5975 - val_loss: 1.4970 - val_accuracy: 0.6520\n",
            "Epoch 17/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.4859 - accuracy: 0.6613 - val_loss: 1.4704 - val_accuracy: 0.5980\n",
            "Epoch 18/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.4594 - accuracy: 0.6282 - val_loss: 1.4453 - val_accuracy: 0.6814\n",
            "Epoch 19/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.4345 - accuracy: 0.6687 - val_loss: 1.4213 - val_accuracy: 0.5490\n",
            "Epoch 20/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.4103 - accuracy: 0.6270 - val_loss: 1.3970 - val_accuracy: 0.6373\n",
            "Epoch 21/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.3858 - accuracy: 0.6417 - val_loss: 1.3743 - val_accuracy: 0.7206\n",
            "Epoch 22/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.3645 - accuracy: 0.6810 - val_loss: 1.3530 - val_accuracy: 0.8284\n",
            "Epoch 23/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.3427 - accuracy: 0.7178 - val_loss: 1.3317 - val_accuracy: 0.7059\n",
            "Epoch 24/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.3219 - accuracy: 0.6859 - val_loss: 1.3118 - val_accuracy: 0.8284\n",
            "Epoch 25/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.3024 - accuracy: 0.7423 - val_loss: 1.2920 - val_accuracy: 0.7598\n",
            "Epoch 26/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.2832 - accuracy: 0.7632 - val_loss: 1.2738 - val_accuracy: 0.6961\n",
            "Epoch 27/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.2646 - accuracy: 0.7190 - val_loss: 1.2557 - val_accuracy: 0.7206\n",
            "Epoch 28/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.2469 - accuracy: 0.7399 - val_loss: 1.2387 - val_accuracy: 0.7010\n",
            "Epoch 29/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.2289 - accuracy: 0.7043 - val_loss: 1.2238 - val_accuracy: 0.7990\n",
            "Epoch 30/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.2137 - accuracy: 0.7509 - val_loss: 1.2075 - val_accuracy: 0.7941\n",
            "Epoch 31/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.1984 - accuracy: 0.8233 - val_loss: 1.1921 - val_accuracy: 0.6422\n",
            "Epoch 32/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.1831 - accuracy: 0.7558 - val_loss: 1.1775 - val_accuracy: 0.8088\n",
            "Epoch 33/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.1684 - accuracy: 0.8098 - val_loss: 1.1627 - val_accuracy: 0.8431\n",
            "Epoch 34/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.1544 - accuracy: 0.8466 - val_loss: 1.1490 - val_accuracy: 0.7990\n",
            "Epoch 35/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.1414 - accuracy: 0.8245 - val_loss: 1.1364 - val_accuracy: 0.7304\n",
            "Epoch 36/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.1282 - accuracy: 0.7791 - val_loss: 1.1242 - val_accuracy: 0.8431\n",
            "Epoch 37/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.1166 - accuracy: 0.8466 - val_loss: 1.1120 - val_accuracy: 0.8431\n",
            "Epoch 38/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.1046 - accuracy: 0.8294 - val_loss: 1.0997 - val_accuracy: 0.9020\n",
            "Epoch 39/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.0929 - accuracy: 0.8785 - val_loss: 1.0894 - val_accuracy: 0.9265\n",
            "Epoch 40/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.0817 - accuracy: 0.8282 - val_loss: 1.0791 - val_accuracy: 0.9167\n",
            "Epoch 41/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.0712 - accuracy: 0.8736 - val_loss: 1.0682 - val_accuracy: 0.8382\n",
            "Epoch 42/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.0607 - accuracy: 0.8221 - val_loss: 1.0574 - val_accuracy: 0.9265\n",
            "Epoch 43/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.0506 - accuracy: 0.8748 - val_loss: 1.0490 - val_accuracy: 0.8873\n",
            "Epoch 44/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.0422 - accuracy: 0.8245 - val_loss: 1.0383 - val_accuracy: 0.9118\n",
            "Epoch 45/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.0327 - accuracy: 0.8761 - val_loss: 1.0291 - val_accuracy: 0.8971\n",
            "Epoch 46/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.0233 - accuracy: 0.8454 - val_loss: 1.0210 - val_accuracy: 0.9069\n",
            "Epoch 47/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 1.0152 - accuracy: 0.8810 - val_loss: 1.0120 - val_accuracy: 0.9216\n",
            "Epoch 48/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.0066 - accuracy: 0.8896 - val_loss: 1.0040 - val_accuracy: 0.9167\n",
            "Epoch 49/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9988 - accuracy: 0.8834 - val_loss: 0.9959 - val_accuracy: 0.9167\n",
            "Epoch 50/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9905 - accuracy: 0.8908 - val_loss: 0.9891 - val_accuracy: 0.9314\n",
            "Epoch 51/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9842 - accuracy: 0.8957 - val_loss: 0.9806 - val_accuracy: 0.9265\n",
            "Epoch 52/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9767 - accuracy: 0.8847 - val_loss: 0.9736 - val_accuracy: 0.9265\n",
            "Epoch 53/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9688 - accuracy: 0.8908 - val_loss: 0.9671 - val_accuracy: 0.9118\n",
            "Epoch 54/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9616 - accuracy: 0.8871 - val_loss: 0.9598 - val_accuracy: 0.9314\n",
            "Epoch 55/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9551 - accuracy: 0.9055 - val_loss: 0.9530 - val_accuracy: 0.9216\n",
            "Epoch 56/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.9485 - accuracy: 0.9006 - val_loss: 0.9479 - val_accuracy: 0.9167\n",
            "Epoch 57/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9438 - accuracy: 0.8994 - val_loss: 0.9405 - val_accuracy: 0.9167\n",
            "Epoch 58/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.9362 - accuracy: 0.9055 - val_loss: 0.9348 - val_accuracy: 0.9216\n",
            "Epoch 59/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.9304 - accuracy: 0.9031 - val_loss: 0.9286 - val_accuracy: 0.9167\n",
            "Epoch 60/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9249 - accuracy: 0.8945 - val_loss: 0.9226 - val_accuracy: 0.9167\n",
            "Epoch 61/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9187 - accuracy: 0.8982 - val_loss: 0.9168 - val_accuracy: 0.9167\n",
            "Epoch 62/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9139 - accuracy: 0.8957 - val_loss: 0.9116 - val_accuracy: 0.9265\n",
            "Epoch 63/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9078 - accuracy: 0.9153 - val_loss: 0.9061 - val_accuracy: 0.9363\n",
            "Epoch 64/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.9030 - accuracy: 0.9092 - val_loss: 0.9013 - val_accuracy: 0.9118\n",
            "Epoch 65/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8977 - accuracy: 0.8994 - val_loss: 0.8956 - val_accuracy: 0.9363\n",
            "Epoch 66/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8927 - accuracy: 0.9202 - val_loss: 0.8910 - val_accuracy: 0.9216\n",
            "Epoch 67/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.8880 - accuracy: 0.8957 - val_loss: 0.8858 - val_accuracy: 0.9216\n",
            "Epoch 68/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8834 - accuracy: 0.9055 - val_loss: 0.8819 - val_accuracy: 0.9265\n",
            "Epoch 69/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8792 - accuracy: 0.9190 - val_loss: 0.8766 - val_accuracy: 0.9412\n",
            "Epoch 70/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8738 - accuracy: 0.9141 - val_loss: 0.8719 - val_accuracy: 0.9412\n",
            "Epoch 71/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8700 - accuracy: 0.9031 - val_loss: 0.8679 - val_accuracy: 0.9265\n",
            "Epoch 72/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8660 - accuracy: 0.9092 - val_loss: 0.8638 - val_accuracy: 0.9265\n",
            "Epoch 73/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8614 - accuracy: 0.9092 - val_loss: 0.8593 - val_accuracy: 0.9314\n",
            "Epoch 74/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8574 - accuracy: 0.9043 - val_loss: 0.8552 - val_accuracy: 0.9314\n",
            "Epoch 75/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8528 - accuracy: 0.9202 - val_loss: 0.8505 - val_accuracy: 0.9314\n",
            "Epoch 76/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8489 - accuracy: 0.9190 - val_loss: 0.8474 - val_accuracy: 0.9461\n",
            "Epoch 77/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8450 - accuracy: 0.9055 - val_loss: 0.8431 - val_accuracy: 0.9314\n",
            "Epoch 78/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8414 - accuracy: 0.9153 - val_loss: 0.8394 - val_accuracy: 0.9461\n",
            "Epoch 79/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.8378 - accuracy: 0.9215 - val_loss: 0.8351 - val_accuracy: 0.9461\n",
            "Epoch 80/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8336 - accuracy: 0.9227 - val_loss: 0.8310 - val_accuracy: 0.9461\n",
            "Epoch 81/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.8305 - accuracy: 0.9117 - val_loss: 0.8283 - val_accuracy: 0.9265\n",
            "Epoch 82/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8268 - accuracy: 0.9166 - val_loss: 0.8247 - val_accuracy: 0.9363\n",
            "Epoch 83/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.8231 - accuracy: 0.9252 - val_loss: 0.8215 - val_accuracy: 0.9412\n",
            "Epoch 84/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8200 - accuracy: 0.9190 - val_loss: 0.8169 - val_accuracy: 0.9412\n",
            "Epoch 85/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8159 - accuracy: 0.9202 - val_loss: 0.8136 - val_accuracy: 0.9461\n",
            "Epoch 86/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8129 - accuracy: 0.9215 - val_loss: 0.8110 - val_accuracy: 0.9216\n",
            "Epoch 87/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8095 - accuracy: 0.9227 - val_loss: 0.8084 - val_accuracy: 0.9363\n",
            "Epoch 88/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8065 - accuracy: 0.9178 - val_loss: 0.8038 - val_accuracy: 0.9314\n",
            "Epoch 89/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8043 - accuracy: 0.9092 - val_loss: 0.8012 - val_accuracy: 0.9314\n",
            "Epoch 90/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.8003 - accuracy: 0.9239 - val_loss: 0.7976 - val_accuracy: 0.9363\n",
            "Epoch 91/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7964 - accuracy: 0.9178 - val_loss: 0.7952 - val_accuracy: 0.9216\n",
            "Epoch 92/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7947 - accuracy: 0.9117 - val_loss: 0.7913 - val_accuracy: 0.9363\n",
            "Epoch 93/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7912 - accuracy: 0.9141 - val_loss: 0.7877 - val_accuracy: 0.9510\n",
            "Epoch 94/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7884 - accuracy: 0.9190 - val_loss: 0.7857 - val_accuracy: 0.9314\n",
            "Epoch 95/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7848 - accuracy: 0.9252 - val_loss: 0.7830 - val_accuracy: 0.9265\n",
            "Epoch 96/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7828 - accuracy: 0.9202 - val_loss: 0.7791 - val_accuracy: 0.9461\n",
            "Epoch 97/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7797 - accuracy: 0.9288 - val_loss: 0.7759 - val_accuracy: 0.9559\n",
            "Epoch 98/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7781 - accuracy: 0.9301 - val_loss: 0.7734 - val_accuracy: 0.9363\n",
            "Epoch 99/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7743 - accuracy: 0.9153 - val_loss: 0.7713 - val_accuracy: 0.9461\n",
            "Epoch 100/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7721 - accuracy: 0.9301 - val_loss: 0.7678 - val_accuracy: 0.9559\n",
            "Epoch 101/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7693 - accuracy: 0.9374 - val_loss: 0.7653 - val_accuracy: 0.9363\n",
            "Epoch 102/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.7665 - accuracy: 0.9276 - val_loss: 0.7625 - val_accuracy: 0.9412\n",
            "Epoch 103/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7637 - accuracy: 0.9313 - val_loss: 0.7610 - val_accuracy: 0.9412\n",
            "Epoch 104/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7619 - accuracy: 0.9202 - val_loss: 0.7573 - val_accuracy: 0.9412\n",
            "Epoch 105/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.9288 - val_loss: 0.7552 - val_accuracy: 0.9461\n",
            "Epoch 106/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.7563 - accuracy: 0.9301 - val_loss: 0.7529 - val_accuracy: 0.9510\n",
            "Epoch 107/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7542 - accuracy: 0.9313 - val_loss: 0.7499 - val_accuracy: 0.9559\n",
            "Epoch 108/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.9325 - val_loss: 0.7471 - val_accuracy: 0.9461\n",
            "Epoch 109/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7488 - accuracy: 0.9313 - val_loss: 0.7447 - val_accuracy: 0.9412\n",
            "Epoch 110/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.9325 - val_loss: 0.7422 - val_accuracy: 0.9461\n",
            "Epoch 111/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.9337 - val_loss: 0.7394 - val_accuracy: 0.9559\n",
            "Epoch 112/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7421 - accuracy: 0.9337 - val_loss: 0.7393 - val_accuracy: 0.9461\n",
            "Epoch 113/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7400 - accuracy: 0.9288 - val_loss: 0.7353 - val_accuracy: 0.9461\n",
            "Epoch 114/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.9239 - val_loss: 0.7330 - val_accuracy: 0.9412\n",
            "Epoch 115/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.9301 - val_loss: 0.7307 - val_accuracy: 0.9461\n",
            "Epoch 116/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7332 - accuracy: 0.9276 - val_loss: 0.7282 - val_accuracy: 0.9559\n",
            "Epoch 117/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.9301 - val_loss: 0.7264 - val_accuracy: 0.9412\n",
            "Epoch 118/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7291 - accuracy: 0.9178 - val_loss: 0.7240 - val_accuracy: 0.9510\n",
            "Epoch 119/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7274 - accuracy: 0.9276 - val_loss: 0.7220 - val_accuracy: 0.9510\n",
            "Epoch 120/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7246 - accuracy: 0.9288 - val_loss: 0.7198 - val_accuracy: 0.9510\n",
            "Epoch 121/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7228 - accuracy: 0.9350 - val_loss: 0.7173 - val_accuracy: 0.9510\n",
            "Epoch 122/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7215 - accuracy: 0.9276 - val_loss: 0.7153 - val_accuracy: 0.9559\n",
            "Epoch 123/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.9350 - val_loss: 0.7132 - val_accuracy: 0.9461\n",
            "Epoch 124/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7167 - accuracy: 0.9350 - val_loss: 0.7116 - val_accuracy: 0.9510\n",
            "Epoch 125/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7150 - accuracy: 0.9227 - val_loss: 0.7105 - val_accuracy: 0.9314\n",
            "Epoch 126/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7124 - accuracy: 0.9301 - val_loss: 0.7080 - val_accuracy: 0.9363\n",
            "Epoch 127/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.9337 - val_loss: 0.7053 - val_accuracy: 0.9559\n",
            "Epoch 128/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.9325 - val_loss: 0.7032 - val_accuracy: 0.9510\n",
            "Epoch 129/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7066 - accuracy: 0.9374 - val_loss: 0.7025 - val_accuracy: 0.9412\n",
            "Epoch 130/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7060 - accuracy: 0.9227 - val_loss: 0.7000 - val_accuracy: 0.9510\n",
            "Epoch 131/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.9313 - val_loss: 0.6975 - val_accuracy: 0.9559\n",
            "Epoch 132/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.7020 - accuracy: 0.9325 - val_loss: 0.6955 - val_accuracy: 0.9461\n",
            "Epoch 133/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.9337 - val_loss: 0.6947 - val_accuracy: 0.9510\n",
            "Epoch 134/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.9337 - val_loss: 0.6916 - val_accuracy: 0.9412\n",
            "Epoch 135/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.9350 - val_loss: 0.6903 - val_accuracy: 0.9559\n",
            "Epoch 136/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.9325 - val_loss: 0.6881 - val_accuracy: 0.9510\n",
            "Epoch 137/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.9313 - val_loss: 0.6866 - val_accuracy: 0.9559\n",
            "Epoch 138/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.9350 - val_loss: 0.6847 - val_accuracy: 0.9461\n",
            "Epoch 139/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.9374 - val_loss: 0.6829 - val_accuracy: 0.9510\n",
            "Epoch 140/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.9362 - val_loss: 0.6819 - val_accuracy: 0.9510\n",
            "Epoch 141/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.9337 - val_loss: 0.6809 - val_accuracy: 0.9510\n",
            "Epoch 142/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.9387 - val_loss: 0.6787 - val_accuracy: 0.9510\n",
            "Epoch 143/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.9313 - val_loss: 0.6765 - val_accuracy: 0.9510\n",
            "Epoch 144/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.9276 - val_loss: 0.6747 - val_accuracy: 0.9559\n",
            "Epoch 145/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.9387 - val_loss: 0.6727 - val_accuracy: 0.9510\n",
            "Epoch 146/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.9350 - val_loss: 0.6720 - val_accuracy: 0.9510\n",
            "Epoch 147/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.9387 - val_loss: 0.6704 - val_accuracy: 0.9510\n",
            "Epoch 148/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.9362 - val_loss: 0.6676 - val_accuracy: 0.9510\n",
            "Epoch 149/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.9362 - val_loss: 0.6658 - val_accuracy: 0.9510\n",
            "Epoch 150/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.9337 - val_loss: 0.6649 - val_accuracy: 0.9510\n",
            "Epoch 151/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.9374 - val_loss: 0.6629 - val_accuracy: 0.9510\n",
            "Epoch 152/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.9337 - val_loss: 0.6609 - val_accuracy: 0.9510\n",
            "Epoch 153/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.9337 - val_loss: 0.6615 - val_accuracy: 0.9461\n",
            "Epoch 154/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.9387 - val_loss: 0.6582 - val_accuracy: 0.9510\n",
            "Epoch 155/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.9362 - val_loss: 0.6578 - val_accuracy: 0.9559\n",
            "Epoch 156/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.9411 - val_loss: 0.6563 - val_accuracy: 0.9559\n",
            "Epoch 157/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.9337 - val_loss: 0.6541 - val_accuracy: 0.9510\n",
            "Epoch 158/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.9337 - val_loss: 0.6528 - val_accuracy: 0.9510\n",
            "Epoch 159/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.9423 - val_loss: 0.6513 - val_accuracy: 0.9510\n",
            "Epoch 160/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.9362 - val_loss: 0.6496 - val_accuracy: 0.9559\n",
            "Epoch 161/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.9350 - val_loss: 0.6483 - val_accuracy: 0.9510\n",
            "Epoch 162/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.9399 - val_loss: 0.6467 - val_accuracy: 0.9510\n",
            "Epoch 163/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.9411 - val_loss: 0.6455 - val_accuracy: 0.9510\n",
            "Epoch 164/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.9399 - val_loss: 0.6452 - val_accuracy: 0.9461\n",
            "Epoch 165/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.9350 - val_loss: 0.6435 - val_accuracy: 0.9559\n",
            "Epoch 166/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.9387 - val_loss: 0.6411 - val_accuracy: 0.9510\n",
            "Epoch 167/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.9374 - val_loss: 0.6403 - val_accuracy: 0.9559\n",
            "Epoch 168/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.9362 - val_loss: 0.6401 - val_accuracy: 0.9461\n",
            "Epoch 169/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.9350 - val_loss: 0.6406 - val_accuracy: 0.9412\n",
            "Epoch 170/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.9337 - val_loss: 0.6363 - val_accuracy: 0.9510\n",
            "Epoch 171/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.9423 - val_loss: 0.6362 - val_accuracy: 0.9510\n",
            "Epoch 172/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.9362 - val_loss: 0.6342 - val_accuracy: 0.9559\n",
            "Epoch 173/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.9399 - val_loss: 0.6335 - val_accuracy: 0.9559\n",
            "Epoch 174/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.9423 - val_loss: 0.6319 - val_accuracy: 0.9510\n",
            "Epoch 175/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.9436 - val_loss: 0.6306 - val_accuracy: 0.9510\n",
            "Epoch 176/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.9399 - val_loss: 0.6285 - val_accuracy: 0.9510\n",
            "Epoch 177/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.9374 - val_loss: 0.6274 - val_accuracy: 0.9510\n",
            "Epoch 178/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.9374 - val_loss: 0.6267 - val_accuracy: 0.9559\n",
            "Epoch 179/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.9399 - val_loss: 0.6262 - val_accuracy: 0.9461\n",
            "Epoch 180/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.9374 - val_loss: 0.6243 - val_accuracy: 0.9510\n",
            "Epoch 181/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.9374 - val_loss: 0.6223 - val_accuracy: 0.9510\n",
            "Epoch 182/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.9399 - val_loss: 0.6214 - val_accuracy: 0.9510\n",
            "Epoch 183/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.9423 - val_loss: 0.6200 - val_accuracy: 0.9510\n",
            "Epoch 184/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.9423 - val_loss: 0.6193 - val_accuracy: 0.9510\n",
            "Epoch 185/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.9362 - val_loss: 0.6195 - val_accuracy: 0.9559\n",
            "Epoch 186/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.9399 - val_loss: 0.6183 - val_accuracy: 0.9461\n",
            "Epoch 187/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.9423 - val_loss: 0.6171 - val_accuracy: 0.9510\n",
            "Epoch 188/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.9350 - val_loss: 0.6147 - val_accuracy: 0.9510\n",
            "Epoch 189/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.9387 - val_loss: 0.6137 - val_accuracy: 0.9559\n",
            "Epoch 190/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.9448 - val_loss: 0.6132 - val_accuracy: 0.9559\n",
            "Epoch 191/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.9411 - val_loss: 0.6116 - val_accuracy: 0.9510\n",
            "Epoch 192/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.9436 - val_loss: 0.6106 - val_accuracy: 0.9510\n",
            "Epoch 193/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.9411 - val_loss: 0.6093 - val_accuracy: 0.9510\n",
            "Epoch 194/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.9423 - val_loss: 0.6080 - val_accuracy: 0.9510\n",
            "Epoch 195/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.9436 - val_loss: 0.6073 - val_accuracy: 0.9510\n",
            "Epoch 196/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.9423 - val_loss: 0.6068 - val_accuracy: 0.9559\n",
            "Epoch 197/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.9362 - val_loss: 0.6084 - val_accuracy: 0.9363\n",
            "Epoch 198/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.9374 - val_loss: 0.6045 - val_accuracy: 0.9510\n",
            "Epoch 199/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.9411 - val_loss: 0.6035 - val_accuracy: 0.9510\n",
            "Epoch 200/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.9448 - val_loss: 0.6029 - val_accuracy: 0.9510\n",
            "Epoch 201/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.9387 - val_loss: 0.6009 - val_accuracy: 0.9510\n",
            "Epoch 202/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.9399 - val_loss: 0.5999 - val_accuracy: 0.9510\n",
            "Epoch 203/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.9399 - val_loss: 0.5993 - val_accuracy: 0.9510\n",
            "Epoch 204/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.6069 - accuracy: 0.9399 - val_loss: 0.5994 - val_accuracy: 0.9559\n",
            "Epoch 205/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.9387 - val_loss: 0.5977 - val_accuracy: 0.9510\n",
            "Epoch 206/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.9436 - val_loss: 0.5973 - val_accuracy: 0.9510\n",
            "Epoch 207/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.9399 - val_loss: 0.5956 - val_accuracy: 0.9510\n",
            "Epoch 208/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.9374 - val_loss: 0.5949 - val_accuracy: 0.9510\n",
            "Epoch 209/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.9387 - val_loss: 0.5933 - val_accuracy: 0.9510\n",
            "Epoch 210/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.9362 - val_loss: 0.5931 - val_accuracy: 0.9510\n",
            "Epoch 211/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.9423 - val_loss: 0.5915 - val_accuracy: 0.9510\n",
            "Epoch 212/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.9411 - val_loss: 0.5914 - val_accuracy: 0.9510\n",
            "Epoch 213/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.9399 - val_loss: 0.5906 - val_accuracy: 0.9510\n",
            "Epoch 214/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.9374 - val_loss: 0.5909 - val_accuracy: 0.9461\n",
            "Epoch 215/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.9423 - val_loss: 0.5881 - val_accuracy: 0.9510\n",
            "Epoch 216/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.9374 - val_loss: 0.5874 - val_accuracy: 0.9510\n",
            "Epoch 217/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.9448 - val_loss: 0.5883 - val_accuracy: 0.9461\n",
            "Epoch 218/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.9448 - val_loss: 0.5864 - val_accuracy: 0.9559\n",
            "Epoch 219/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.9423 - val_loss: 0.5850 - val_accuracy: 0.9559\n",
            "Epoch 220/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.9411 - val_loss: 0.5831 - val_accuracy: 0.9510\n",
            "Epoch 221/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.9387 - val_loss: 0.5833 - val_accuracy: 0.9510\n",
            "Epoch 222/300\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5917 - accuracy: 0.9448 - val_loss: 0.5822 - val_accuracy: 0.9510\n",
            "Epoch 223/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.9448 - val_loss: 0.5821 - val_accuracy: 0.9510\n",
            "Epoch 224/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.9362 - val_loss: 0.5804 - val_accuracy: 0.9510\n",
            "Epoch 225/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.9399 - val_loss: 0.5824 - val_accuracy: 0.9461\n",
            "Epoch 226/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.9436 - val_loss: 0.5794 - val_accuracy: 0.9510\n",
            "Epoch 227/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.9411 - val_loss: 0.5795 - val_accuracy: 0.9510\n",
            "Epoch 228/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.9337 - val_loss: 0.5790 - val_accuracy: 0.9461\n",
            "Epoch 229/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.9423 - val_loss: 0.5775 - val_accuracy: 0.9559\n",
            "Epoch 230/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.9436 - val_loss: 0.5761 - val_accuracy: 0.9559\n",
            "Epoch 231/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.9448 - val_loss: 0.5745 - val_accuracy: 0.9510\n",
            "Epoch 232/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.9399 - val_loss: 0.5748 - val_accuracy: 0.9559\n",
            "Epoch 233/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.9387 - val_loss: 0.5741 - val_accuracy: 0.9510\n",
            "Epoch 234/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.9448 - val_loss: 0.5742 - val_accuracy: 0.9510\n",
            "Epoch 235/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.9423 - val_loss: 0.5728 - val_accuracy: 0.9559\n",
            "Epoch 236/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.9399 - val_loss: 0.5713 - val_accuracy: 0.9559\n",
            "Epoch 237/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.9362 - val_loss: 0.5703 - val_accuracy: 0.9510\n",
            "Epoch 238/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.9448 - val_loss: 0.5700 - val_accuracy: 0.9510\n",
            "Epoch 239/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.9423 - val_loss: 0.5687 - val_accuracy: 0.9559\n",
            "Epoch 240/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.9362 - val_loss: 0.5685 - val_accuracy: 0.9510\n",
            "Epoch 241/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.9387 - val_loss: 0.5685 - val_accuracy: 0.9510\n",
            "Epoch 242/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.9399 - val_loss: 0.5672 - val_accuracy: 0.9510\n",
            "Epoch 243/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.9448 - val_loss: 0.5671 - val_accuracy: 0.9510\n",
            "Epoch 244/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.9411 - val_loss: 0.5652 - val_accuracy: 0.9510\n",
            "Epoch 245/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.9411 - val_loss: 0.5638 - val_accuracy: 0.9510\n",
            "Epoch 246/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.9399 - val_loss: 0.5635 - val_accuracy: 0.9510\n",
            "Epoch 247/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.9411 - val_loss: 0.5641 - val_accuracy: 0.9510\n",
            "Epoch 248/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.9485 - val_loss: 0.5630 - val_accuracy: 0.9510\n",
            "Epoch 249/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.9411 - val_loss: 0.5624 - val_accuracy: 0.9559\n",
            "Epoch 250/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.9436 - val_loss: 0.5615 - val_accuracy: 0.9559\n",
            "Epoch 251/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.9374 - val_loss: 0.5608 - val_accuracy: 0.9510\n",
            "Epoch 252/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.9485 - val_loss: 0.5605 - val_accuracy: 0.9510\n",
            "Epoch 253/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.9399 - val_loss: 0.5598 - val_accuracy: 0.9559\n",
            "Epoch 254/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.9448 - val_loss: 0.5605 - val_accuracy: 0.9510\n",
            "Epoch 255/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.9387 - val_loss: 0.5589 - val_accuracy: 0.9559\n",
            "Epoch 256/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.9448 - val_loss: 0.5574 - val_accuracy: 0.9510\n",
            "Epoch 257/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.9472 - val_loss: 0.5568 - val_accuracy: 0.9510\n",
            "Epoch 258/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.9423 - val_loss: 0.5552 - val_accuracy: 0.9510\n",
            "Epoch 259/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.9374 - val_loss: 0.5556 - val_accuracy: 0.9510\n",
            "Epoch 260/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.9448 - val_loss: 0.5569 - val_accuracy: 0.9412\n",
            "Epoch 261/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.9485 - val_loss: 0.5537 - val_accuracy: 0.9510\n",
            "Epoch 262/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.9411 - val_loss: 0.5528 - val_accuracy: 0.9510\n",
            "Epoch 263/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.9411 - val_loss: 0.5520 - val_accuracy: 0.9510\n",
            "Epoch 264/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.9399 - val_loss: 0.5524 - val_accuracy: 0.9510\n",
            "Epoch 265/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.9423 - val_loss: 0.5522 - val_accuracy: 0.9510\n",
            "Epoch 266/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.9436 - val_loss: 0.5506 - val_accuracy: 0.9510\n",
            "Epoch 267/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.9423 - val_loss: 0.5510 - val_accuracy: 0.9559\n",
            "Epoch 268/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.9436 - val_loss: 0.5496 - val_accuracy: 0.9510\n",
            "Epoch 269/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.9448 - val_loss: 0.5479 - val_accuracy: 0.9510\n",
            "Epoch 270/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.9411 - val_loss: 0.5477 - val_accuracy: 0.9510\n",
            "Epoch 271/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.9436 - val_loss: 0.5470 - val_accuracy: 0.9510\n",
            "Epoch 272/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.9460 - val_loss: 0.5471 - val_accuracy: 0.9510\n",
            "Epoch 273/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.9436 - val_loss: 0.5471 - val_accuracy: 0.9510\n",
            "Epoch 274/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.9436 - val_loss: 0.5450 - val_accuracy: 0.9510\n",
            "Epoch 275/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.9399 - val_loss: 0.5447 - val_accuracy: 0.9559\n",
            "Epoch 276/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.9411 - val_loss: 0.5449 - val_accuracy: 0.9510\n",
            "Epoch 277/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.9411 - val_loss: 0.5440 - val_accuracy: 0.9510\n",
            "Epoch 278/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.9460 - val_loss: 0.5436 - val_accuracy: 0.9510\n",
            "Epoch 279/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.9448 - val_loss: 0.5436 - val_accuracy: 0.9510\n",
            "Epoch 280/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.9448 - val_loss: 0.5425 - val_accuracy: 0.9510\n",
            "Epoch 281/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.9387 - val_loss: 0.5411 - val_accuracy: 0.9510\n",
            "Epoch 282/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.9436 - val_loss: 0.5417 - val_accuracy: 0.9559\n",
            "Epoch 283/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.9460 - val_loss: 0.5407 - val_accuracy: 0.9510\n",
            "Epoch 284/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.9423 - val_loss: 0.5402 - val_accuracy: 0.9510\n",
            "Epoch 285/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.9436 - val_loss: 0.5402 - val_accuracy: 0.9510\n",
            "Epoch 286/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.9448 - val_loss: 0.5389 - val_accuracy: 0.9510\n",
            "Epoch 287/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.9472 - val_loss: 0.5398 - val_accuracy: 0.9559\n",
            "Epoch 288/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.9399 - val_loss: 0.5384 - val_accuracy: 0.9510\n",
            "Epoch 289/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.9436 - val_loss: 0.5390 - val_accuracy: 0.9461\n",
            "Epoch 290/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.9485 - val_loss: 0.5362 - val_accuracy: 0.9510\n",
            "Epoch 291/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.9472 - val_loss: 0.5360 - val_accuracy: 0.9510\n",
            "Epoch 292/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.9436 - val_loss: 0.5349 - val_accuracy: 0.9510\n",
            "Epoch 293/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.9472 - val_loss: 0.5355 - val_accuracy: 0.9510\n",
            "Epoch 294/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.9485 - val_loss: 0.5356 - val_accuracy: 0.9510\n",
            "Epoch 295/300\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.9411 - val_loss: 0.5347 - val_accuracy: 0.9510\n",
            "Epoch 296/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.9472 - val_loss: 0.5344 - val_accuracy: 0.9510\n",
            "Epoch 297/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.9423 - val_loss: 0.5333 - val_accuracy: 0.9510\n",
            "Epoch 298/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.9436 - val_loss: 0.5339 - val_accuracy: 0.9510\n",
            "Epoch 299/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.9460 - val_loss: 0.5326 - val_accuracy: 0.9510\n",
            "Epoch 300/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.9423 - val_loss: 0.5327 - val_accuracy: 0.9510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzpWol0DwOln",
        "outputId": "7bdd20e4-d4b6-473b-892c-e89cd9171d23"
      },
      "source": [
        "loss, accuracy = model.evaluate(x_val, y_val_encoded, verbose=0)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9509803652763367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "vwVOukwzxEDE",
        "outputId": "e680fe84-26bc-4a34-cd99-7471d3ffe692"
      },
      "source": [
        "# loss graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "FKdZj85gxhyr",
        "outputId": "61a27e75-2f3f-4899-fdd8-352d1572308b"
      },
      "source": [
        "# accuracy graph\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_accuracy', 'val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgoQXPZ6t4Qk"
      },
      "source": [
        "6.  **If the accuracy is more than 95%, we are almost done.**\n",
        "7.  **If the accuracy is not more than 95%, find the other regularizers or epochs. (Maybe the input data is wrong...)**\n",
        "8.  **Predict the class with testing data (use test .csv file)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEx7IpgHt1Bv",
        "outputId": "94537ef6-b14c-4482-9c72-f6a58f27a7b7"
      },
      "source": [
        "#import the testing .csv file\n",
        "test_data_all = pd.read_csv('sample_data/sensory_data_test.csv')\n",
        "\n",
        "# test data preprocessing\n",
        "x_test = test_data_all.drop(['__id__', 'tapped_zone', 'tap_position_x', 'tap_position_y'], axis=1)  # Drop evertyig except sensory data\n",
        "y_test = test_data_all.tapped_zone  # only the tapping zone\n",
        "\n",
        "# drop the wrong record\n",
        "x_test = x_test.dropna()\n",
        "y_test = y_test.dropna()\n",
        "\n",
        "# one-hot encoding for test target\n",
        "y_test_encoded = tf.keras.utils.to_categorical(y_test)  \n",
        "\n",
        "# check out the shape\n",
        "print(x_test.shape)\n",
        "print(y_test_encoded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26, 6)\n",
            "(26, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d_QjgTPvNrW",
        "outputId": "f731db0d-6bef-4912-9735-26495a55359c"
      },
      "source": [
        "loss2, accuracy2 = model.evaluate(x_test, y_test_encoded, verbose=0)\n",
        "print(accuracy2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9230769276618958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vvAgX7atjOT"
      },
      "source": [
        "## Guess we have a meaningful experiment result!\n",
        "\n",
        "*   Accuaracy of testing data looks not beautiful...\n",
        "\n",
        "\n",
        "    1.   Suspicious about Overfitting\n",
        "    2.   Suspicious about Data Collection (How to collect more clean, more accurate sensory data?)\n",
        "    3.   Suspicious about neural network depth\n",
        "    4.   Suspicious about the regularization (L1? or L2?)\n",
        "\n",
        "\n",
        "*   Proceed to the next step? (Inference the every zones)\n",
        "\n"
      ]
    }
  ]
}